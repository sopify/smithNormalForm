README

This program takes a matrix over the integers and transforms it into its Smith normal form, a.k.a. invariant factor form. Smith form for matrices over the integers is useful when studying the structure of finitely-generated abelian groups, or solving linear equations over the integers.

Currently, the program diagonalizes a matrix, with diagonal elements all positive, ordered by size. However, I still need to implement a Euclidean algorithm to transform the diagonal terms into Smith form.

The following works in Ubuntu 11.10. Here's what I type in when I want to execute the code:
1) cd to the directory you save the file in
2) $ gcc smithNormalForm.c
3) $ ./a.out

Eventually, I will add functionality to input a matrix from a text file or if the user wishes, from the Terminal itself. I hope you enjoy it.